主题：
    * 1. 目标识别
    2. 目标侦测

    3. 目标分隔
    4. 目标跟踪
任务：
    1. 图像的卷积处理；
    2. 使用求导的方法实现梯度下降
    3. 实现特征学习
    4. 实现卷积神经网络LeNet-5

技术：
    1. 向量与图像
    2. 张量与自动求导
    3. 梯度下降的算法
    4. 深度学习网络（BP网络）
        4.1. 掌握集中卷积神经网络
    5. 数据集的处理

1. 图像的表示与矩阵
    - 图像在计算内部的表示：矩阵
        - 通过矩阵操作了解图像处理的技术
    - OpenCV中：
        矩阵：cv::Mat 
            |
        numpy.ndarray
        numpy.mat
    - 安装：
        - OpenCV --|----numpy.ndarray
        - numpy  --|
        pip install numpy
        --------------------------------------
        pip install opencv-python
        pip install opencv-python -i https://pypi.tuna.tsinghua.edu.cn/simple/
        pip install opencv-contrib-python
        pip install opencv-contrib-python -i https://pypi.tuna.tsinghua.edu.cn/simple/
        --------------------------------------
        强烈建议：安装opencv使用cmake源代码编译安装
    - python类的使用
        1. 构造器使用方式
            HWC  - uint8
            图像的深度：
                通道
                每个通道的类型
        2. 函数产生对象：工厂模式
    - 矩阵的基本操作：    
        1. 元素访问[]
            1.1. 数, 数列表
            1.2. 切片 
            1.3. 逻辑值

        2. 运算符 + - * / //  %  **   < > >= <= ==

2. 梯度特征与卷积运算
    图像特征：
        统计特征（直方）
    梯度特征:
        像素的变化：数学建模：一阶导数（Sobel），二阶导数（Laplace）
    梯度特征的表示（数学模型）
        卷积核：特征获取的过程 = 卷积运算
            特征由卷积核决定
            需要的特征，通过学习卷积核得到对分类有帮助的特征。（ ）
    机器学习：神经网络：卷积神经网络
        卷积神经网络：卷积特征学习网络 + 分类网络(逻辑回归) 
        1张图 - 100个1*1小图（每个图一个特征）
        原图 -卷积> 特征图 -卷积> 特征图 -> 分类器 -> 误差 
    问题：
        怎么根据误差调整卷积核？
            - 数学模型
            - 梯度下降算法 -> 总是是收敛的
    注意：
        new_pixel = scale * pixel + delta 
        因为pixel经过梯度运算可能很小。所以设计scale,delta进行一个线性运算，是的像素可视。

3. 张量与数据集（MNIST手写数字数据集）
    #1. 张量 -图> 跟踪施加在张量上的运算 
    #2. 张量 <-> 向量
    1. 张量 <-> 图像

    # 格式：Tensor （NCHW）：N样本数，C样本的通道Channel，H高度，W宽度

4. 自动求导与梯度下降
    x -= x' * a    
    a: 学习率
    x'：控制下降方向


5. 使用pytroch实现卷积神经网络
    x 图像(1 * 1 * 28* 28) -> 6 * 5 * 5 -(padding=2)> 6 *  28 * 28    6*k1  
        |
        池化（2 * 2） ->  6 * 14 * 14  -> relu -> 6 * 14 * 14

    6 * 14 * 14 -> 16 * 5 * 5 -(padding=0)> 16 *  10 * 10             16*k2   
        |
        池化（2 * 2） -> 16 * 5 * 5 -> relu - > 16 * 5 * 5

    16 * 5 * 5 -> 120 * 5 * 5 -> 120 * 1 * 1                          120*k3
        |
        relu -> 120 * 1 * 1
                    |
                    [120]                                            1*w1(120, 84)
                    |
                    84                                               1*w2(84, 10)
                    |
                    10 (softmax/sigmoid) -> 10长的概率向量
                                                |
                                                取概率大的分量作为识别的结果

                                                |
                                                与实际标签做误差计算: 最小 
                                                    loss.backward()
                                        找到6，16， 120，1，1个矩阵，是的loss最小
                                            loss.backward()
                                            k1 -= k1.grad * lr
                                            k2 -= k2.grad * lr
                                            k3 -= k3.grad * lr
                                            w1 -= w1.grad * lr
                                            w2 -= w2.grad * lr


任务：
    01. 运行上课的代码，理解梯度特征与卷积运算的关系
    02. 深度学习的原理
        模型：机器特征运算 + 分类器
        过程：计算误差，并根据误差更新卷积核
    03. 修改其中学习率，轮数，观察误差下降的极限。

    04. 关注其中运算的数据格式。
    
